{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a014bc93",
   "metadata": {},
   "source": [
    "# Section 1: Goal & Imports\n",
    "\n",
    "**Explanation**  \n",
    "We aim to predict the critical temperature (TC) of materials using machine learning. Steps:\n",
    "1. Expand features using matminer (Magpie descriptors).\n",
    "2. Split data into train/test and perform EDA.\n",
    "3. Compare Random Forest performance with and without Magpie features using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dd28f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from matminer.featurizers.conversions import StrToComposition\n",
    "from matminer.featurizers.composition import ElementProperty\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "plt.rcParams['axes.grid'] = False\n",
    "print('Imports OK')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582e2057",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "- Why do we need feature expansion for material properties?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c7ffc2-0fe3-4600-8537-c71154f3b599",
   "metadata": {},
   "source": [
    "## Section 2: Load Dataset\n",
    "**Explanation** \n",
    "- We load a dataset of materials with their critical temperature (TC).\n",
    "- Important: Ensure the file path is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7409c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = Path('..') / 'data' / 'DS1.csv'\n",
    "assert csv_path.exists(), f\"Could not find {csv_path}. Adjust the path if you moved the file.\"\n",
    "\n",
    "# Load data\n",
    "df0 = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efab85f",
   "metadata": {},
   "source": [
    "**Task**  \n",
    "- Check the first 5 rows of df0. What columns are present?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e50097-6c26-4394-adc0-80a8e3ddc676",
   "metadata": {},
   "source": [
    "## Section 3: Feature Expansion with Matminer\n",
    "**Explanation**  \n",
    "- StrToComposition converts chemical formula strings into composition objects.\n",
    "- ElementProperty adds Magpie descriptors (statistics of elemental properties).\n",
    "- This increases feature richness for better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b8c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df0.copy()\n",
    "df = StrToComposition().featurize_dataframe(df, 'Name')\n",
    "ep = ElementProperty.from_preset(preset_name='magpie',impute_nan=True)\n",
    "df = ep.featurize_dataframe(df, col_id='composition')\n",
    "print('After Magpie expansion:', df.shape)\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e15309",
   "metadata": {},
   "source": [
    "**Questions**  \n",
    "- How many features were added after Magpie expansion?\n",
    "- Why might imputation (impute_nan=True) be necessary?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa46d03-05c7-4f46-88a5-1b2a61ad7186",
   "metadata": {},
   "source": [
    "## Section 4: Train/Test Split\n",
    "**Explanation**  \n",
    "- We separate original numeric features and Magpie-augmented features.\n",
    "- Rule: Use train for EDA and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcc7a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = df['TC']\n",
    "X_mag_all = df.drop(columns=['TC']).select_dtypes(include=[np.number])\n",
    "X_orig_all = df0.drop(columns=['TC']).select_dtypes(include=[np.number])\n",
    "mask = y_all.notna()\n",
    "y_all = y_all.loc[mask]\n",
    "X_mag_all = X_mag_all.loc[mask]\n",
    "X_orig_all = X_orig_all.loc[mask]\n",
    "X_orig_train, X_orig_test, y_train, y_test = train_test_split(\n",
    "    X_orig_all, y_all, test_size=0.30, random_state=123, shuffle=True\n",
    ")\n",
    "X_mag_train = X_mag_all.loc[X_orig_train.index]\n",
    "X_mag_test  = X_mag_all.loc[X_orig_test.index]\n",
    "X_orig_train.shape, X_mag_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57949897",
   "metadata": {},
   "source": [
    "**Task**  \n",
    "- Print shapes of X_orig_train and X_mag_train. Which has more features? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6df638c-82ec-4b4e-8257-fbc06c3cb467",
   "metadata": {},
   "source": [
    "## Section 5: EDA on Training Data\n",
    "**Explanation**  \n",
    "- Use describe() to understand TC distribution.\n",
    "- Histogram shows skew and range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d31f0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame({'TC_train': y_train}).describe())\n",
    "plt.figure(figsize=(6.2, 4.0))\n",
    "plt.hist(y_train, bins=30, color='tab:blue', alpha=0.85, edgecolor='white')\n",
    "plt.xlabel('TC [train]'); plt.ylabel('count')\n",
    "plt.title('Histogram: TC (train)')\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d841d5f8",
   "metadata": {},
   "source": [
    "**Qestions**\n",
    "- What does the five-number summary tell you about TC?\n",
    "- Is TC distribution skewed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f617e4ee-6b59-4db4-955b-e10aa1d5511a",
   "metadata": {},
   "source": [
    "## Section 6: Correlation Analysis\n",
    "**Explanation**  \n",
    "- Find top Magpie features correlated with TC.\n",
    "- Helps identify which features might be most predictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b0021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "const_mask = X_mag_train.nunique(dropna=False) > 1\n",
    "Xc = X_mag_train.loc[:, const_mask]\n",
    "corr_series = Xc.corrwith(y_train)\n",
    "corr_abs = corr_series.abs().sort_values(ascending=False)\n",
    "topk = 20\n",
    "top_feats = corr_abs.head(topk).index.tolist()\n",
    "top_corr = corr_series.loc[top_feats].sort_values(key=lambda s: s.abs(), ascending=True)\n",
    "plt.figure(figsize=(8.0, 5.0))\n",
    "colors = ['tab:red' if v<0 else 'tab:green' for v in top_corr.values]\n",
    "plt.barh(top_corr.index, top_corr.values, color=colors)\n",
    "plt.axvline(0, color='k', lw=1)\n",
    "plt.xlabel('Pearson r (feature, TC) [train]')\n",
    "plt.title(f'Top {topk} features by |correlation| with TC (train)')\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96fcb8c",
   "metadata": {},
   "source": [
    "**Task**  \n",
    "Which feature has the strongest positive correlation with TC?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c678c514-e20c-4227-a664-06de3dca416b",
   "metadata": {},
   "source": [
    "## Section 7: Model Comparison with Cross-Validation\n",
    "**Explanation**  \n",
    "Compare Random Forest on original vs Magpie features using 5-fold cross validation (CV).  \n",
    "Metric: R² (higher is better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c05859",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_orig = RandomForestRegressor(random_state=123)\n",
    "rf_mag = RandomForestRegressor(random_state=123)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "scores_orig = cross_val_score(rf_orig, X_orig_train, y_train, scoring='r2', cv=cv)\n",
    "scores_mag  = cross_val_score(rf_mag,  X_mag_train,  y_train, scoring='r2', cv=cv)\n",
    "print('R^2 (orig) folds:', np.round(scores_orig, 4))\n",
    "print('R^2 (mag ) folds:', np.round(scores_mag,  4))\n",
    "print('Mean±Std R^2 (orig): {:.4f} ± {:.4f}'.format(scores_orig.mean(), scores_orig.std()))\n",
    "print('Mean±Std R^2 (mag ): {:.4f} ± {:.4f}'.format(scores_mag.mean(),  scores_mag.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87305662",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "- Which feature set performs better? Why might that be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b013547",
   "metadata": {},
   "source": [
    "## Optional: Test Evaluation & Feature Importance\n",
    "**Explanation**  \n",
    "Evaluate on test set and inspect feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28abc432",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_orig.fit(X_orig_train, y_train)\n",
    "rf_mag.fit(X_mag_train, y_train)\n",
    "y_pred_orig = rf_orig.predict(X_orig_test)\n",
    "y_pred_mag  = rf_mag.predict(X_mag_test)\n",
    "def report(y_true, y_pred, label):\n",
    "    r2  = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    print(f'{label} - R^2: {r2:.4f}, MAE: {mae:.3f}')\n",
    "\n",
    "report(y_test, y_pred_orig, 'TEST RF (original)')\n",
    "report(y_test, y_pred_mag,  'TEST RF (+Magpie)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304dd226-2e0a-48b3-b372-fdbf1eb50477",
   "metadata": {},
   "source": [
    "**Task**  \n",
    "- Which model generalizes better to test data?\n",
    "- Why is MAE useful alongside R²?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8307f57-0a71-4dbe-917d-33f883615d2e",
   "metadata": {},
   "source": [
    "#### Create a feature imptortance\n",
    "The RandomforestRegressor provides a feature importance which reflects how much each feature reduces impurity across trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41059e1-3c42-4581-87a0-c7dc9d7dbf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names that went into the pipeline (imputer doesn't change names)\n",
    "feat_names_orig = X_orig_train.columns\n",
    "\n",
    "# Importance values\n",
    "imp_orig = rf_orig.feature_importances_\n",
    "\n",
    "# Build a table and plot top-20\n",
    "fi_orig = (pd.DataFrame({'feature': feat_names_orig, 'importance': imp_orig})\n",
    "             .sort_values('importance', ascending=False)\n",
    "             .head(20))\n",
    "\n",
    "plt.figure(figsize=(7.5, 5.0))\n",
    "plt.barh(fi_orig['feature'][::-1], fi_orig['importance'][::-1], color='tab:gray')\n",
    "plt.xlabel('Feature importance (Gini-based)')\n",
    "plt.title('Random Forest Feature Importances — Original features (top-20)')\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "fi_orig.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb3cc37-0717-4858-9973-03dfae3bc813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
